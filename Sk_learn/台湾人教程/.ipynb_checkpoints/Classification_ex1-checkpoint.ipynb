{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm,metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('data', array([[  0.,   0.,   5., ...,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  10.,   0.,   0.],\n",
       "       [  0.,   0.,   0., ...,  16.,   9.,   0.],\n",
       "       ..., \n",
       "       [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "       [  0.,   0.,   2., ...,  12.,   0.,   0.],\n",
       "       [  0.,   0.,  10., ...,  12.,   1.,   0.]])), ('target', array([0, 1, 2, ..., 8, 9, 8])), ('target_names', array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])), ('images', array([[[  0.,   0.,   5., ...,   1.,   0.,   0.],\n",
       "        [  0.,   0.,  13., ...,  15.,   5.,   0.],\n",
       "        [  0.,   3.,  15., ...,  11.,   8.,   0.],\n",
       "        ..., \n",
       "        [  0.,   4.,  11., ...,  12.,   7.,   0.],\n",
       "        [  0.,   2.,  14., ...,  12.,   0.,   0.],\n",
       "        [  0.,   0.,   6., ...,   0.,   0.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,   0., ...,   5.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,   9.,   0.,   0.],\n",
       "        [  0.,   0.,   3., ...,   6.,   0.,   0.],\n",
       "        ..., \n",
       "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "        [  0.,   0.,   1., ...,   6.,   0.,   0.],\n",
       "        [  0.,   0.,   0., ...,  10.,   0.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,   0., ...,  12.,   0.,   0.],\n",
       "        [  0.,   0.,   3., ...,  14.,   0.,   0.],\n",
       "        [  0.,   0.,   8., ...,  16.,   0.,   0.],\n",
       "        ..., \n",
       "        [  0.,   9.,  16., ...,   0.,   0.,   0.],\n",
       "        [  0.,   3.,  13., ...,  11.,   5.,   0.],\n",
       "        [  0.,   0.,   0., ...,  16.,   9.,   0.]],\n",
       "\n",
       "       ..., \n",
       "       [[  0.,   0.,   1., ...,   1.,   0.,   0.],\n",
       "        [  0.,   0.,  13., ...,   2.,   1.,   0.],\n",
       "        [  0.,   0.,  16., ...,  16.,   5.,   0.],\n",
       "        ..., \n",
       "        [  0.,   0.,  16., ...,  15.,   0.,   0.],\n",
       "        [  0.,   0.,  15., ...,  16.,   0.,   0.],\n",
       "        [  0.,   0.,   2., ...,   6.,   0.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,   2., ...,   0.,   0.,   0.],\n",
       "        [  0.,   0.,  14., ...,  15.,   1.,   0.],\n",
       "        [  0.,   4.,  16., ...,  16.,   7.,   0.],\n",
       "        ..., \n",
       "        [  0.,   0.,   0., ...,  16.,   2.,   0.],\n",
       "        [  0.,   0.,   4., ...,  16.,   2.,   0.],\n",
       "        [  0.,   0.,   5., ...,  12.,   0.,   0.]],\n",
       "\n",
       "       [[  0.,   0.,  10., ...,   1.,   0.,   0.],\n",
       "        [  0.,   2.,  16., ...,   1.,   0.,   0.],\n",
       "        [  0.,   0.,  15., ...,  15.,   0.,   0.],\n",
       "        ..., \n",
       "        [  0.,   4.,  16., ...,  16.,   6.,   0.],\n",
       "        [  0.,   8.,  16., ...,  16.,   8.,   0.],\n",
       "        [  0.,   1.,   8., ...,  12.,   1.,   0.]]])), ('DESCR', \"Optical Recognition of Handwritten Digits Data Set\\n===================================================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\nReferences\\n----------\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\")])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#digits为一个dict型数据\n",
    "digits.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (1797, 64)\n",
      "target (1797,)\n",
      "target_names (10,)\n",
      "images (1797, 8, 8)\n",
      "DESCR\n"
     ]
    }
   ],
   "source": [
    "for key, value in digits.items():\n",
    "    try:\n",
    "        print(key, value.shape)\n",
    "    except:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据的形式为矩阵\n",
    "type(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkvkfiDN/okZBD1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa58b320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#查看images和target\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2,4, index+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap =plt.cm.gray_r, interpolation = 'nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练及分类 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "n_samples = len(digits.images)\n",
    "print(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#transform images to data\n",
    "data = digits.images.reshape(n_samples, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = svm.SVC(gamma = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data[:n_samples/2], digits.target[:n_samples/2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if __name__ == '__main__':\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "expected = digits.target[n_samples/2:]\n",
    "predicted = model.predict(data[n_samples/2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 4, 9, 0, 8, 9, 8, 1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 4, 9, 0, 8, 9, 8, 1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型准确度 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    }
   ],
   "source": [
    "#一般用confusion_matrix与classification_report\n",
    "print('Confusion matrix: \\n%s'\n",
    "     % metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上矩阵表示：实际为x,被预测为y的统计情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: \\n%s'\n",
    "     % metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上为完整的精度、召回率报告。f1-score = 2*precision*recall/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAABpCAYAAAD1EqK9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACjZJREFUeJzt3XuMXFUdwPHvjxaQQGghoBFot/JIUIkt+MLE2AZRAtpY\n/8BnYksEbZQgBuKbtPiIIVEsxGg0GkooRg1JWxAJYuhuxEfkISU8/5B2RWxQxK68JEGPf9y7ZJjd\ne+52dne6Z+f7STbdmXMf5/567++emfntmUgpIUkqywH7uwOSpH1n8pakApm8JalAJm9JKpDJW5IK\nZPKWpALN2eQdEcsiIkXEwvrxLRGxtg/73RgRW2Z7P70yLhMZk4mMyUTzLSbTTt4RsTsino+IZyLi\niYjYHBGHzUTnOqWUzk4pXTvF/pw50/vv2P4ZEXFPRPw7Ih6NiE9k+mFcJvZhYGLSsZ+P1Unj/IY+\nDExMImJ1RNxfH+/vIuJ1DX0YpJisiIi7I+K5+t8VU1lvpkbeq1NKhwGnAW8CvtLVuYiIOTvKn6qI\nOBDYCvwAWAR8ELgyIpY3rGJcJhqImIyLiCOALwEPZBYbiJhExEnA9cB6YDFwE3Dj+Ei4y6DE5CBg\nO7AFOAK4FtheP581owefUnocuAU4JSKGI+IbEfFb4Dng+IhYFBE/jog9EfF4RHw9IhbUB7EgIr4V\nEU9GxKPAe7oOcrhz5BIRF0TEQxHxdEQ8GBGnRcR1wFLgpvqu/bl62dPru/zeiNgZEas6tvOaiBip\nt3MbcFTmEI8EDgeuS5U7gYeACaMH45KPywDEZNw3gauBJ9sWHICYnAXckVK6I6X0InAFcCywcoBj\nsgpYCGxKKb2QUroaCOCMzDovBWdaP8Bu4Mz69yVUI4yvAcPAX4DX153rHJ0dCrwS+CPwyXrd9cDD\n9TaOBHYACVhYtw8D59e/nws8Dry5PtATgaHu/tSPjwX+CZxDdbN6V/346Lr998CVwMHAO4CngS0d\n698HfKTj8U+ATwMLgLcBfweWGJf2uAxgTN4C3FVv66U+DWpMgAuBX3a0LQD+A3xmgGPyWeCWruO/\nCbikNffOUPJ+BtgLjALfAw6pA/PVjuVeBbwAHNLx3IeBHfXvtwPrO9renQn0rd3/4ZP9x9ePP081\nIuxc5lZgLdUd9UXg0K4ktCVzvKuBJ+r1XgQuMC5Ti8sgxYQqMd0FnN7dpwGOycnAs1SjzYOAy4D/\nAV8c4JhcBvy067nrgY1N19r4z2TvNfViTUrp151PRATAYx1PDVHdKffUbVDdtcaXOaZr+dHM/pYA\nf55i34aAcyNidcdzB1LdhY8B/pVSerZrv0sm21BEnAz8DHg/cBtwEvCLiPhbSunmSVYxLhPjMhAx\nAT4F3JdS+sMU9jsQMUkpPRxVdcd3gVdTvc/7IPDXSRYfiJhQ3aQO73puEdVoPWumkneT1PH7Y1R3\nyaNS9X5Xtz28/ACXZrb7GHDCFPY5vux1KaULuheMiCHgiIg4tCPYSyfZxrhTgEdSSrfWjx+JiJuB\ns4HJkncT45Lv33yIyTuBlRFxTv34SODUiFiRUrow09+m/s2HmJBSugG4oV5/MfBx4M5MX3P9mw8x\neQC4JCIi1cNu4A1UN7isvn1am1LaA/wK+HZEHB4RB0TECRGxsl7k58BFEXFcVJ/QfyGzuR8Bl0bE\nG6NyYh00qF66H9+x7BZgdUScVX+A8YqIWBURx6WURqle2l4eEQdFxNupXv43+RNwYlRlcRERJwDv\npXoPqyfGZaJ5EpN1wGuBFfXPXcDlwJf3JRbj5klMqPe5ICKOBn4I3JhSenhf4wHzJibDwH/rfh4c\nERdRJfrbpxKAmXjP+8xJnh+m6z0+qpcD36d6mTRGddF/qG5bCHyH6o3/XVQffk36/lT9eD3wCNXL\njvuBU+vn30f1ocZe4NL6ubcCI8BTwD+oRoNL67bjgd/U27mN6o7X+eHCA8BHOx5/oN7f0/VxXAEc\nYFza4zJoMWk7xkGMCXBHfY48Rf1BozHhVOBu4HngnvH9tv1EvbIkqSDFF7lL0iAyeUtSgUzeklQg\nk7ckFcjkLUkFmq0/0umphGXv3r3Z9nXr1jW23XvvvT1td3h4OLvPFSuyszNGrrFLTzHZvHlztn3j\nxo2NbaOjzX9QtnXr1sa2NWvWtHUrZ9Zj0ib3f5o7tk2bNjW25c69KZj1mLRdO7nzJHeOrVq1qqdt\nwoxeOzBL58qyZct6asvFLLfeFEw5Lo68JalAJm9JKpDJW5IKZPKWpAKZvCWpQCZvSSrQbM/nPUGu\npClXlgSwc+fOxraVK1c2to2MjDS2bdu2LbvPlnKnGbF79+7GtvPOO6/v+yzdxRdf3NiWK+OaZonk\nftXW99x5nDsXei3PbdvnXJErd8zFJZer2uKyePHill5NjSNvSSqQyVuSCmTylqQCmbwlqUAmb0kq\nkMlbkgrU91LB3MxtuVJAgB07djS25cp6cqWCc72cadGiRdn2sbGxntYtuSwudw5B/jzatWtXY9tM\nlXDtD22zCuZKJHPlstu3b29sm+vXDuTLRiGfN3JxybW1zVQ6U9eeI29JKpDJW5IKZPKWpAKZvCWp\nQCZvSSqQyVuSCmTylqQC9b3OO1cb2lbTnKvvzdVrDg0NNbbNhXrnXA1uW01zr1PG5upU22pj+yFX\nK9v2reUbNmxobOu13nkunCc5bedJ7tvOc9dO7ppsm8K5X3L9v+qqq7Lr5s6VnNz50DYlrHXekjTA\nTN6SVCCTtyQVyOQtSQUyeUtSgUzeklSgvpcKTqfEJvdN1rlpQJcvX97ar7mqrSxu7dq1jW25Uq5c\niWFbCVg/pgLNlb61Td2aK3XMlczlYrJ169bsPvd3KWHb/1mvZX259XIlev2Uyxtt137b9dWLfk0t\n7Mhbkgpk8pakApm8JalAJm9JKpDJW5IKZPKWpAL1vVQwJzfjG7R/Q3aTXBlhrnQM8uWJMyV3XKOj\no9l1c2VxuZK+XFlc27dfz1SpYO64c99anpslEvJleyMjI+0dm0TbudkPubK26ZRP5uTK8PpVEtem\n17wwHbm49GtWTkfeklQgk7ckFcjkLUkFMnlLUoFM3pJUIJO3JBVoTpUKtsmV/PVqf5QZdcuVXOVm\nDYTeZ0WbC18s2+txt81mlyvry5UK5vbZj5kU2+RK0NpmNcyVtuXKYcfGxhrb5kL5JOT7P51S4Nx1\nkItnv64fR96SVCCTtyQVyOQtSQUyeUtSgUzeklQgk7ckFcjkLUkFipTSbGx3Vjaaq2XN1f7m6om3\nbduW3WfLtJeRXfnleopJrp4U8jHJTSd7zTXXNLZNcxrcWY9Jm16/IX7Xrl2NbdOsad7vMcnVqef+\nfmLDhg2NbdP85vV9iQn0GJe2v+PIneu9Tvs6zSlhpxwXR96SVCCTtyQVyOQtSQUyeUtSgUzeklQg\nk7ckFWi2SgUlSbPIkbckFcjkLUkFMnlLUoFM3pJUIJO3JBXI5C1JBTJ5S1KBTN6SVCCTtyQVyOQt\nSQUyeUtSgUzeklQgk7ckFcjkLUkFMnlLUoFM3pJUIJO3JBXI5C1JBTJ5S1KBTN6SVCCTtyQVyOQt\nSQUyeUtSgf4Pzo8FS1wpb+QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa912400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#同样可以画出images和预测结果\n",
    "images_and_predictions = list(zip(digits.images[n_samples/2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:5]):\n",
    "    plt.subplot(2,5,index+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap = plt.cm.gray_r)\n",
    "    plt.title('Predicted:%i' % prediction)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
